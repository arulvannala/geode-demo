version: '3.2'
networks:
  default:
    ipam:
      driver: default
      config:
        - subnet: 172.19.0.0/24

services:
  dns:
    image: coredns/coredns:1.2.0
    command: -conf /etc/coredns/Corefile
    container_name: dns
    networks:
      default:
        ipv4_address: 172.19.0.2
        aliases: [ns1.localhost]
    ports:
      - "5300:53/udp"
    volumes:
      - ./docker/dns:/etc/coredns

  locator:
    image: apachegeode/geode
    container_name: locator
    hostname: locator.localhost
    depends_on: [dns]
    dns: [172.19.0.2]
    networks:
      default:
        aliases: [locator.localhost]
    expose:
      - "10334"
      - "1099"
      - "7575"
    #  - "1024"
    ports:
      - "1099:1099"
      - "10334:10334"
      - "7575:7575"
      - "7070:7070"
    volumes:
      - ./docker/:/docker/
    command: /docker/geode/gfshWrapper.sh gfsh start locator --name=locator.localhost --mcast-port=0

  server:
    image: apachegeode/geode
    container_name: server
    hostname: server.localhost
    depends_on: [dns, locator]
    dns: [172.19.0.2]
    networks:
      default:
        aliases: [server.localhost]
    links:
      - locator:locator
    expose:
      - "8080"
      - "40404"
      - "1099"
    ports:
      - "40404:40404"
      - "7071:7070"
    volumes:
      - ./docker/:/docker/
    command: /docker/geode/startServer.sh --server-port=40404 --max-heap=1G

  geode-config:
    image: alpine
    depends_on: [dns, server, locator]
    container_name: geode-config
    volumes:
      - ./docker:/docker
    command: docker/geode/setup.sh

  mysql:
    image: mysql:5.7.25
    container_name: mysql
    depends_on: [dns]
    hostname: mysql.localhost
    dns: [172.19.0.2]
    networks:
      default:
        aliases: [mysql.localhost]
    environment:
      MYSQL_DATABASE: dataflow
      MYSQL_USER: root
      MYSQL_ROOT_PASSWORD: rootpw
    expose:
      - 3306
  kafka:
    image: landoop/fast-data-dev:1.1.0
    container_name: kafka
    depends_on: [dns]
    hostname: kafka.localhost
    dns: [172.19.0.2]
    networks:
      default:
        aliases: [kafka.localhost]
    environment:
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - SAMPLEDATA=0
      - RUNTESTS=0
    ports:
      - "2181:2181"
      - "9092:9092"
      - "3030:3030"
      - "8081:8081"

  dataflow-server:
    image: springcloud/spring-cloud-dataflow-server:2.1.2.RELEASE
    container_name: dataflow
    hostname: dataflow.localhost
    dns: [172.19.0.2]
    networks:
      default:
        aliases: [dataflow.localhost]
    ports:
      - "9393:9393"
      - "9995-9998:9995-9998"
    environment:
      - spring.cloud.dataflow.applicationProperties.stream.spring.cloud.stream.kafka.binder.brokers=PLAINTEXT://kafka:9092
      - spring.cloud.dataflow.applicationProperties.stream.spring.cloud.stream.kafka.streams.binder.brokers=PLAINTEXT://kafka:9092
      - spring.cloud.dataflow.applicationProperties.stream.spring.cloud.stream.kafka.binder.zkNodes=zookeeper:2181
      - spring.cloud.dataflow.applicationProperties.stream.spring.cloud.stream.kafka.streams.binder.zkNodes=zookeeper:2181
      - spring.cloud.skipper.client.serverUri=http://skipper.localhost:7577/api
      - spring.cloud.dataflow.applicationProperties.stream.management.metrics.export.influx.enabled=true
      - spring.cloud.dataflow.applicationProperties.stream.management.metrics.export.influx.db=myinfluxdb
      - spring.cloud.dataflow.applicationProperties.stream.management.metrics.export.influx.uri=http://influxdb:8086
      - logging.level=DEBUG
      - spring.cloud.dataflow.grafana-info.url=http://localhost:3000
      - SPRING_DATASOURCE_URL=jdbc:mysql://mysql:3306/dataflow
      - SPRING_DATASOURCE_USERNAME=root
      - SPRING_DATASOURCE_PASSWORD=rootpw
      - SPRING_DATASOURCE_DRIVER_CLASS_NAME=org.mariadb.jdbc.Driver
    depends_on:
      - kafka
      - dns
    volumes:
      - '~/.m2:/root/.m2'

  app-import:
    image: springcloud/openjdk:latest
    container_name: scdf-app-import
    depends_on:
      - dataflow-server
    command: >
      /bin/sh -c "
        while ! nc -z dataflow-server 9393;
        do
          sleep 1;
        done;

        curl -H 'Accept: application/json' -X POST 'http://dataflow.localhost:9393/apps/processor/transform/0.0.1-SNAPSHOT' -i \
            -d 'uri=file://root/.m2/repository/io/enfuse/pipeline/transform/0.0.1-SNAPSHOT/transform-0.0.1-SNAPSHOT.jar' \
            -d 'force=true'

        curl -H 'Accept: application/json' -X POST 'http://dataflow.localhost:9393/apps/source/http/2.1.0.RELEASE' -i \
            -d 'uri=file://root/.m2/repository/org/springframework/cloud/stream/app/http-source-kafka/2.1.0.RELEASE/http-source-kafka-2.1.0.RELEASE.jar' \
            -d 'metadata-uri://root/.m2/repository/org/springframework/cloud/stream/app/http-source-kafka/2.1.0.RELEASE/http-source-kafka-2.1.0.RELEASE-metadata.jar' \
            -d 'force=true'

        curl -H 'Accept: application/json' -X POST 'http://dataflow.localhost:9393/apps/sink/log/2.1.1.RELEASE' -i \
            -d 'uri=file://root/.m2/repository/org/springframework/cloud/stream/app/log-sink-kafka/2.1.1.RELEASE/log-sink-kafka-2.1.1.RELEASE.jar' \
            -d 'metadata-uri://root/.m2/repository/org/springframework/cloud/stream/app/log-sink-kafka/2.1.1.RELEASE/log-sink-kafka-2.1.1.RELEASE-metadata.jar' \
            -d 'force=true'


        echo 'SCDF Apps imported'"


  skipper-server:
    image: springcloud/spring-cloud-skipper-server:2.0.3.RELEASE
    container_name: skipper
    depends_on: [dns]
    hostname: skipper.localhost
    dns: [172.19.0.2]
    networks:
      default:
        aliases: [skipper.localhost]
    ports:
      - "7577:7577"
      - "9000-9010:9000-9010"
      - "20000-20105:20000-20105"
    environment:
      - SPRING_CLOUD_SKIPPER_SERVER_PLATFORM_LOCAL_ACCOUNTS_DEFAULT_PORTRANGE_LOW=20000
      - SPRING_CLOUD_SKIPPER_SERVER_PLATFORM_LOCAL_ACCOUNTS_DEFAULT_PORTRANGE_HIGH=20100
      - SPRING_DATASOURCE_URL=jdbc:mysql://mysql:3306/dataflow
      - SPRING_DATASOURCE_USERNAME=root
      - SPRING_DATASOURCE_PASSWORD=rootpw
      - SPRING_DATASOURCE_DRIVER_CLASS_NAME=org.mariadb.jdbc.Driver
    volumes:
      - '~/.m2:/root/.m2'

  influxdb:
    image: influxdb:1.7.4
    container_name: 'influxdb'
    hostname: influxdb.localhost
    depends_on: [dns]
    dns: [172.19.0.2]
    networks:
      default:
        aliases: [influxdb.localhost]
    ports:
      - '8086:8086'

  grafana:
    image: springcloud/spring-cloud-dataflow-grafana-influxdb:2.1.2.RELEASE
    container_name: grafana
    hostname: grafana.localhost
    depends_on: [dns, influxdb]
    dns: [172.19.0.2]
    networks:
      default:
        aliases: [grafana.localhost]
    ports:
      - "3000:3000"




  postgres:
    image: postgres:9.6
    depends_on: [dns]
    dns: [172.19.0.2]
    container_name: postgres
    networks:
      default:
        aliases: [postgres.localhost]
    ports:
      - "5432:5432"
      # environment:
      # - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      # - ./pgdata:/var/lib/postgresql/data/pgdata
      - ./docker/postgres/initdb:/docker-entrypoint-initdb.d

volumes:
  scdf-targets:
